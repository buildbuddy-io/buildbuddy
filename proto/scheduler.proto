syntax = "proto3";

import "google/rpc/status.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";
import "proto/acl.proto";
import "proto/context.proto";
import "proto/trace.proto";

package scheduler;

message NodeAddress {
  // The node's hostname. Must be reachable from the scheduler.
  string host = 1;

  // The node's port.
  int32 port = 2;
}

message LeaseTaskRequest {
  // The task for which to request a lease. If successful, a LeaseTaskResponse
  // will be returned containing the serialized task and duration of the lease.
  string task_id = 1;

  // Indicates that the leased task has been completed and can be deleted.
  // Mutually exclusive with `release`.
  bool finalize = 2;

  // DEPRECATED
  // Indicates that the lease should be released without finalizing (deleting)
  // the task.
  // Mutually exclusive with `finalize`.
  bool release = 3;

  // ID of the executor making the request.
  string executor_id = 4;

  // Indicates that the leased task could not be run to completion and should
  // be re-enqueued to be retried.
  bool re_enqueue = 5;
  // Optional description of why the task needs to be re-enqueued (may be
  // visible to end user).
  google.rpc.Status re_enqueue_reason = 6;

  // Indicates whether the client supports lease reconnection.
  //
  // When set to true, and the client is attempting to lease a task that is in
  // "reconnecting" state, the server will use the `reconnect_token` to validate
  // the lease attempt. If the token is invalid, the server will return a
  // NOT_FOUND error.
  //
  // Otherwise (if this field is false), the server will treat tasks in
  // "reconnecting" state the same way that it treats unclaimed tasks. This
  // behavior ensures backwards compatibility for older executors which don't
  // support reconnection.
  bool supports_reconnect = 7;

  // The token issued by the server when initially establishing the lease. This
  // should be set by the client when attempting to retry a disconnected lease.
  string reconnect_token = 8;
}

message LeaseTaskResponse {
  // The serialized task will be set in the *first* LeaseTaskResponse returned.
  // from the server. Subsequent responses will *only* include a lease duration.
  bytes serialized_task = 1;

  // The remaining duration of this lease. To continue to hold the lease, the
  // client *must* send another LeaseTaskRequest before time.Now() +
  // lease_duration_seconds.
  int64 lease_duration_seconds = 2;

  // Whether or not the lease was closed cleanly.
  bool closed_cleanly = 3;

  // A token that may be used to retry the lease if it disconnects.
  // DEPRECATED: updated executors will use the lease_id as the reconnect token.
  string reconnect_token = 4;

  // ID for this lease. The scheduler will ignore any mutation requests if the
  // provided lease ID doesn't match the current lease ID.
  string lease_id = 5;

  // If true, indicates that the client may reclaim an existing lease by
  // resending a LeaseTaskRequest with the same lease_id.
  bool supports_reconnect = 6;
}

// CustomResource represents a user-defined resource.
// These are the remote equivalent of bazel's --local_extra_resources flag.
message CustomResource {
  // Name of the resource, which does not include the "resources:" prefix.
  // Ex: "gpu_memory_gb"
  string name = 1;

  // Requested resource amount.
  float value = 2;
}

message TaskSize {
  // The tasks's estimated memory usage.
  int64 estimated_memory_bytes = 1;

  // The task's estimated cpu usage.
  int64 estimated_milli_cpu = 2;

  // The task's estimated disk space requirement (beyond task inputs).
  int64 estimated_free_disk_bytes = 3;

  // The task's estimated disk bytes read per second.
  int64 disk_read_bps = 5;

  // The task's estimated disk bytes written per second.
  int64 disk_write_bps = 6;

  // The task's estimated disk read IO operations per second.
  int64 disk_read_iops = 7;

  // The task's estimated disk write IO operations per second.
  int64 disk_write_iops = 8;

  // The task's custom resource requirement.
  //
  // These are requested explicitly using platform properties prefixed with
  // "resources:". For a task to be assigned to an executor, the executor must
  // be configured with enough custom resource capacity to satisfy all of the
  // resource requests in this list.
  repeated CustomResource custom_resources = 4;
}

// CgroupSettings defines Linux cgroup2 options for an execution.
//
// See https://www.kernel.org/doc/Documentation/admin-guide/cgroup-v2.rst
//
// Note that proto3 optional is used for scalar fields below. If values are not
// present, then the executor should leave them at the cgroup2 default values.
message CgroupSettings {
  // Proportion of CPU given to this task relative to other tasks in the parent
  // cgroup. This provides for a best-effort CPU guarantee.
  //
  // Values 1 to 10000 are supported.
  //
  // Maps to "cpu.weight" in cgroup2.
  optional int64 cpu_weight = 1;

  // Maximum CPU usage allowed per quota period.
  //
  // Maps to the "cpu.max" quota field in cgroup2.
  optional int64 cpu_quota_limit_usec = 2;

  // How often the CPU quota is refreshed. Longer periods may allow for higher
  // burst CPU usage but may result in more stalling if the quota is exhausted
  // very early in the period.
  //
  // Maps to the "cpu.max" period field in cgroup2.
  optional int64 cpu_quota_period_usec = 3;

  // CPU time that can be "borrowed" from other quota periods to allow for burst
  // CPU usage, in usec.
  //
  // Maps to "cpu.max.burst" in cgroup2.
  optional int64 cpu_max_burst_usec = 4;

  // The requested minimum utilization (protection) as a percentage rational
  // number, e.g. 12.34 for 12.34%.
  //
  // Maps to "cpu.uclamp.min" in cgroup2.
  optional float cpu_uclamp_min = 5;

  // The requested maximum utilization (limit) as a percentage rational
  // number, e.g. 98.76 for 98.76%.
  //
  // Maps to "cpu.uclamp.max" in cgroup2.
  optional float cpu_uclamp_max = 6;

  // Hard limit on the number of processes allowed in the cgroup.
  //
  // Maps to "pids.max" in cgroup2.
  optional int64 pids_max = 7;

  // Limit after which memory usage is throttled and processes are put under
  // heavy reclaim pressure.
  //
  // Maps to the "memory.high" field in cgroup2.
  optional int64 memory_throttle_limit_bytes = 8;

  // Limit after which processes in the cgroup are killed by the OOM killer.
  //
  // Maps to the "memory.max" field in cgroup2.
  optional int64 memory_limit_bytes = 9;

  // Best-effort memory protection - if the cgroup and its descendants are below
  // this threshold then memory won't be reclaimed unless memory can't be
  // reclaimed from other unprotected cgroups.
  //
  // Maps to "memory.low" in cgroup2.
  optional int64 memory_soft_guarantee_bytes = 10;

  // Guaranteed minimum memory that can never be reclaimed by the system. If
  // there is not enough memory to provide this guarantee then the OOM killer
  // will be invoked.
  //
  // Maps to "memory.min" in cgroup2.
  optional int64 memory_minimum_bytes = 11;

  // Determines whether the cgroup should be treated as an indivisible workload
  // by the OOM killer. If set, all tasks belonging to the cgroup or to its
  // descendants (if the memory cgroup is not a leaf cgroup) are killed together
  // or not at all. This can be used to avoid partial kills to guarantee
  // workload integrity.
  optional bool memory_oom_group = 12;

  // Throttle limit for anonymous swap memory.
  //
  // Maps to "memory.swap.high" in cgroup2.
  optional int64 swap_throttle_limit_bytes = 13;

  // Hard limit for anonymous swap memory.
  //
  // Maps to "memory.swap.max" in cgroup2.
  optional int64 swap_limit_bytes = 14;

  // Basic IO quality of service mechanism defined in terms of a single latency
  // target number. Specifies the number of microseconds a process can wait
  // before IO from other processes is given to it.
  //
  // Maps to "io.latency" in cgroup2. The major/minor device numbers are not
  // defined here because these may differ from one executor to another.
  optional int64 block_io_latency_target_usec = 15;

  // Proportion of IO time given to this task relative to other tasks in the
  // parent cgroup. This weight is applied only to the disk where all action IO
  // is performed. Other IO block devices receive the default weight.
  //
  // Values 1 to 10000 are supported.
  //
  // Maps to "io.weight" in cgroup2. The major/minor device numbers are not
  // defined here because these may differ from one executor to another.
  optional int64 block_io_weight = 16;

  // IO limit for the block device where all action IO is performed.
  //
  // Maps to "io.max" in cgroup2. The major/minor device numbers are not defined
  // here because these may differ from one executor to another.
  BlockIOLimits block_io_limit = 17;

  message BlockIOLimits {
    // Max read operations per second.
    optional int64 riops = 1;

    // Max write operations per second.
    optional int64 wiops = 2;

    // Max read bytes per second.
    optional int64 rbps = 3;

    // Max write bytes per second.
    optional int64 wbps = 4;
  }

  // CPUSet: the set of cpus that a task may run on. This field is set by the
  // executor, based on the estimated task size. Any value set by the app is
  // ignored.
  repeated int32 cpuset_cpus = 18;

  // CPUSet: the numa node that a task may run on. This field is set by the
  // executor, based on the estimated task size. Any value set by the app is
  // ignored.
  optional int32 numa_node = 19;
}

// Next ID: 9
message SchedulingMetadata {
  // DEPRECATED. This field has two different meanings:
  // 1. The execution server sets this to the task size "estimate" which only
  //    incorporates the default task size and user-requested size, and not any
  //    historical information or model predictions. This estimate is now split
  //    into two separate fields: default_task_size and requested_size.
  // 2. Just before enqueueing a task on an executor, the scheduler sets this to
  //    the "final" task size that should be used by the executor, which
  //    incorporates the measured size or model-predicated size as applicable.
  //    In this case, EnqueueTaskReservationRequest.task_size should be used
  //    instead.
  TaskSize task_size = 1 [deprecated = true];

  // A default task size based on some hard-coded parameters. For example,
  // non-test actions may be given some default task size, test actions
  // declaring TEST_SIZE=large in their environment variables may be given a
  // predefined number of resources, etc. If no better estimate is available,
  // this is the size that is used when scheduling the task on an executor.
  TaskSize default_task_size = 13;

  // Task size measured from a previous task execution of a similar task, if
  // such data is available.
  TaskSize measured_task_size = 7;

  // Task size computed via prediction model. This is only necessary when a
  // measured task size is not available.
  TaskSize predicted_task_size = 8;

  // The resources explicitly requested by the user. These will be unset if the
  // user did not explicitly request resources.
  //
  // These should NOT be used for scheduling purposes. See comments on other
  // TaskSize fields in this message to understand how tasks are sized for
  // scheduling.
  TaskSize requested_task_size = 10;

  string os = 2;
  string arch = 3;
  string pool = 4;
  // Group ID that owns the executors on which the task is to be executed.
  // May be different from the Group ID of the user that issued the Execute
  // request.
  string executor_group_id = 5;
  // Group ID of the user that issued the Execute request.
  string task_group_id = 6;

  // A signal to the executor that the size of this queued task should be
  // tracked as part of the queued-or-assigned size metrics. This is necessary
  // because tasks may be scheduled on multiple executors, but should only
  // contributed to this system-wide metric once, so the scheduler must inform
  // exactly one of the executors to perform the queued task size tracking.
  // This is for metrics purposes only and shouldn't affect the behavior of the
  // scheduler or the executor.
  bool track_queued_task_size = 9;

  // Optional task priority hint. Tasks with *lower* priority values will be
  // prioritized over tasks with higher priority values, on a best-effort basis.
  // Assigning priorities to tasks does not provide any strong guarantees about
  // execution ordering.
  //
  // The default priority is 0, and priorities can be negative.
  //
  // In a multi-tenant scenario, this value does not affect the relative
  // priority of tasks belonging to different groups; it only affects the
  // relative priority of tasks within a group.
  int32 priority = 11;

  // cgroup2 settings. Will be set only for Linux executions.
  CgroupSettings cgroup_settings = 12;
}

message ScheduleTaskRequest {
  string task_id = 1;
  SchedulingMetadata metadata = 2;

  // Serialized build.bazel.remote.execution.v2.ExecutionTask. That proto
  // depends on this one, so using the full type would create a build cycle.
  // We could move ExecutionTask to this file to fix this.
  bytes serialized_task = 3;
}

message ScheduleTaskResponse {
  // Intentionally left blank.
}

message ReEnqueueTaskRequest {
  string task_id = 1;
  // Optional reason for the re-enqueue (may be visible to end-user).
  string reason = 2;
  // Lease ID of the claim on the task. The request will be ignored if the
  // lease ID doesn't match the current lease ID.
  string lease_id = 3;
}

message ReEnqueueTaskResponse {
  // Intentionally left blank.
}

message EnqueueTaskReservationRequest {
  string task_id = 1;
  TaskSize task_size = 2;
  SchedulingMetadata scheduling_metadata = 3;

  // If set, enqueue the task reservation on the given executor instance if it
  // is directly connected to the scheduler that receives this request.
  //
  // If unset, or if there is no such connected executor, select any directly
  // connected executor suitable for running the task.
  //
  // Ex. "610a4cd4-3c0f-41bb-ad72-abe933837d58"
  string executor_id = 4;

  // If set, the executor client should wait this long before making the task
  // available for scheduling. The server will set this field when re-enqueuing
  // tasks that are currently in "reconnecting" state, so that the client which
  // is trying to reconnect its lease can have a short grace period during which
  // it can retry the lease.
  google.protobuf.Duration delay = 5;

  // Used to propagate trace information from the initial Execute request.
  // Normally trace information is automatically propagated via RPC metadata but
  // that doesn't work for streamed task reservations since there's one
  // long-running streaming RPC from the executor to the scheduler.
  trace.Metadata trace_metadata = 100;
}

message EnqueueTaskReservationResponse {
  string task_id = 1;
}

message RegisterExecutorRequest {
  ExecutionNode node = 1;
}

// AskForMoreWorkRequest may be sent from the executor to the scheduler when
// the executor detects it is idle. If more unclaimed work is available, the
// scheduler may enqueue some of it on this executor.
message AskForMoreWorkRequest {}

// AskForMoreWorkResponse is sent from the scheduler to executor in reply to
// AskForMoreWorkRequest. It indicates the minimum amount of time the executor
// must wait before sending another AskForMoreWorkRequest.
message AskForMoreWorkResponse {
  google.protobuf.Duration delay = 1;
}

message ShuttingDownRequest {
  // Task IDs that are in the executor queue.
  repeated string task_id = 1;
}

message RegisterAndStreamWorkRequest {
  // Only one of the fields should be sent. oneofs not used due to awkward Go
  // APIs.

  // Request to register the executor with the scheduler.
  // This message should be sent immediately after establishing stream and be
  // resent periodically as long as the executor should continue to receive task
  // reservations.
  RegisterExecutorRequest register_executor_request = 1;

  // Response to a previous EnqueueTaskReservationRequest.
  EnqueueTaskReservationResponse enqueue_task_reservation_response = 2;

  // Notifications to the scheduler that this executor is going away.
  ShuttingDownRequest shutting_down_request = 3;

  // Request more work, if idle.
  AskForMoreWorkRequest ask_for_more_work_request = 4;
}

message RegisterAndStreamWorkResponse {
  // Request to enqueue a task reservation. A EnqueueTaskReservationResponse
  // message will be sent to ack the task reservation.
  EnqueueTaskReservationRequest enqueue_task_reservation_request = 3;

  // How long to backoff if a AskForMoreWorkRequest was sent.
  AskForMoreWorkResponse ask_for_more_work_response = 4;
}

service Scheduler {
  rpc RegisterAndStreamWork(stream RegisterAndStreamWorkRequest)
      returns (stream RegisterAndStreamWorkResponse) {}

  rpc LeaseTask(stream LeaseTaskRequest) returns (stream LeaseTaskResponse) {}

  rpc ScheduleTask(ScheduleTaskRequest) returns (ScheduleTaskResponse) {}

  rpc ReEnqueueTask(ReEnqueueTaskRequest) returns (ReEnqueueTaskResponse) {}

  // Request to enqueue a task reservation for an existing task to a locally
  // chosen executor.
  rpc EnqueueTaskReservation(EnqueueTaskReservationRequest)
      returns (EnqueueTaskReservationResponse) {}
}

message ExecutionNode {
  // Remote execution node host.
  // Ex. "10.52.6.5"
  string host = 1;

  // Remote execution node port.
  // Ex. 1987
  int32 port = 2 [deprecated = true];

  // Assignable memory bytes in remote execution node.
  // Ex. 26843545600
  int64 assignable_memory_bytes = 3;

  // Assignable cpu in remote execution node.
  // Ex. 7000
  int64 assignable_milli_cpu = 4;

  // Assignable custom resources.
  repeated CustomResource assignable_custom_resources = 11;

  // Remote execution node operating system.
  // Ex. "linux".
  string os = 5;

  // Architecture of the remote execution node.
  // Ex. "amd64"
  string arch = 6;

  // Remote execution pool that this node is assigned to.
  // Ex. "buildbuddy-executors-us-west1-b"
  string pool = 7;

  // Version of the executor binary.
  string version = 8;

  // Unique ID that identifies this executor instance within a node pool. It is
  // set once when the executor binary starts and preserved for the lifetime of
  // the executor. Each executor generates its own ID on startup.
  //
  // Ex. "34c5cf7e-b3b1-4e20-b43c-3e196b30d983"
  string executor_id = 9;

  // ID of the host this executor is running on
  //
  // Ex. "8BiY6U0F"
  string executor_host_id = 10;
}

message GetExecutionNodesRequest {
  context.RequestContext request_context = 1;
}

message GetExecutionNodesResponse {
  context.ResponseContext response_context = 1;

  repeated Executor executor = 2;

  message Executor {
    ExecutionNode node = 1;

    // Whether tasks will be routed to this node by default.
    bool is_default = 2;
  }

  bool user_owned_executors_supported = 3;
}

// Persisted information about connected executors.
message RegisteredExecutionNode {
  ExecutionNode registration = 1;
  string scheduler_host_port = 2;
  string group_id = 3;
  acl.ACL acl = 4;
  google.protobuf.Timestamp last_ping_time = 5;
}
